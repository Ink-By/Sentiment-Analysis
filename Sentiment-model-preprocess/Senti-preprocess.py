import sys
import os

# ê°€ìƒ í™˜ê²½ì˜ site-packages ê²½ë¡œë¥¼ ì¶”ê°€
venv_path = "/opt/anaconda3/envs/roatG/lib/python3.8/site-packages"
sys.path.append(venv_path)

from konlpy.tag import Mecab
from soynlp.normalizer import repeat_normalize

# Initialize tools
mecab = Mecab(dicpath="./mecab-dict/mecab-ko-dic-2.1.1-20180720")

# SentiWord_Dict.txt íŒŒì¼ ì½ê¸°
def load_sentiword_dict(filepath):
    sentiword_dict = {}
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) >= 2:
                word = parts[0]
                try:
                    score = int(parts[1])
                    sentiword_dict[word] = score
                except ValueError:
                    pass
                    # print(f"Skipping line due to invalid score: {line.strip()}")
    return sentiword_dict

# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_text(text):
    # ë¶ˆí•„ìš”í•œ ë°˜ë³µ ì •ê·œí™” (ã…‹ã…‹ã…‹ -> ã…‹ã…‹)
    normalized_sent = repeat_normalize(text, num_repeats=2)
    return normalized_sent

# ê°ì„± ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜
def calculate_sentiment_score(text, sentiword_dict):
    tokens = mecab.morphs(text)
    score = 0
    token_scores = []
    for token in tokens:
        if token in sentiword_dict:
            token_score = sentiword_dict[token]
            score += token_score
            token_scores.append((token, token_score))
        else:
            token_scores.append((token, 0))
    return score, token_scores

# SentiWord_Dict.txt íŒŒì¼ ê²½ë¡œ
filepath = './datasets/SentiWord_Dict.txt'
sentiword_dict = load_sentiword_dict(filepath)

# ë¦¬ë·° ë°ì´í„° ì˜ˆì œ
reviews = [
    "ê²Œì„ì´ ì •ë§ ì¬ë¯¸ìˆìŠµë‹ˆë‹¤. ìºë¦­í„° ë””ìì¸ì´ ì•„ì£¼ ë§ˆìŒì— ë“¤ì–´ìš”. ğŸ˜Š",
    "ì—…ë°ì´íŠ¸ ì´í›„ì— ë²„ê·¸ê°€ ë„ˆë¬´ ë§ì•„ì¡Œì–´ìš”. ê·¸ë˜í”½ì€ ì¢‹ì€ë° í”Œë ˆì´í•˜ê¸° í˜ë“¤ì–´ìš”. ğŸ˜‘",
    "ìŠ¤í† ë¦¬ê°€ ë„ˆë¬´ ê°ë™ì ì´ì—ìš”. ìœ ì € ì¸í„°í˜ì´ìŠ¤ë„ í¸ë¦¬í•˜ê³  ì¢‹ì•„ìš”. ğŸ’œ",
    "ì´ ê²Œì„ì€ ì •ë§ ê°“ê²œì…ë‹ˆë‹¤! í˜œìê²Œì„ì´ì—ìš”.",
    "ì •ë§ ì§€ë£¨í•˜ê³  ì§œì¦ë‚˜ëŠ” ê²Œì„ì´ë„¤ìš”. ë§ê²œì…ë‹ˆë‹¤."
]

# ê° ë¦¬ë·°ì— ëŒ€í•´ ê°ì„± ì ìˆ˜ ê³„ì‚°
review_scores = []
for review in reviews:
    preprocessed_review = preprocess_text(review)
    score, token_scores = calculate_sentiment_score(preprocessed_review, sentiword_dict)
    review_scores.append((review, preprocessed_review, score, token_scores))

# ê²°ê³¼ ì¶œë ¥
for review, preprocessed_review, score, token_scores in review_scores:
    print(f"Original Review: {review}")
    print(f"Preprocessed Review: {preprocessed_review}")
    print(f"Sentiment Score: {score}")
    print("Token scores:")
    for token, token_score in token_scores:
        print(f"  {token}: {token_score}")
    print()
